---
title: "p8105_hw2_yx2858"
author: "Yueyi Xu"
date: "2023-10-01"
output: github_document
---

```{r, message=FALSE}
library(tidyverse) #load library tidyverse
library(dplyr)
```

# Problem 1

# Problem 2
```{r, message=FALSE}
Wheel_df =
  readxl::read_excel("202309 Trash Wheel Collection Data.xlsx",
  sheet = "Mr. Trash Wheel",   #read the dataset with sheet and range
  range = "A2:N586") |>
  janitor::clean_names() |>   #clean the names
  drop_na("dumpster") |>   #omit na values
  mutate(homes_powered = weight_tons*500/30,   #calculate the homes_powered variable
         year = as.integer(year),   #change to numerical variable
         additional_dataset = "Mr. Trash")   #specify the dataset
```

#### Description of Wheel_df:
This Wheel_df dataset contains `r nrow(Wheel_df)` observations and `r names(Wheel_df)` variables. The variable "homes_powered" is calculated using the existing variable "weight_tons" to determine each ton of trash equates to, on average 500 kilowatts of electricity an average household will use 30 kilowatts per day. The additional variable of "additional_dataset" specifies the corresponding data to the "Mr. Trash" category. This way, after merging the three datasets, "Mr. Trash" will be easily distinguished from the rest.

```{r, message=FALSE}
Professor_df =
  readxl::read_excel("202309 Trash Wheel Collection Data.xlsx",
  sheet = "Professor Trash Wheel",   #read the dataset with sheet and range
  range = "A2:M108") |>
  janitor::clean_names() |>   #clean the names
  drop_na("dumpster") |>   #omit na values
  mutate(homes_powered = weight_tons*500/30,   #calculate the homes_powered variable
         additional_dataset = "Professor Trash")   #specify the dataset
```

#### Description of Professor_df:
This Professor_df dataset contains `r nrow(Professor_df)` observations and `r names(Professor_df)` variables. The total weight of trash collected by Professor Trash Wheel is `r sum(Professor_df$weight_tons)` tons. The variable "homes_powered" is calculated using the existing variable "weight_tons" to determine each ton of trash equates to, on average 500 kilowatts of electricity an average household will use 30 kilowatts per day. The additional variable of "additional_dataset" specifies the corresponding data to the "Professor Trash" category. This way, after merging the three datasets, "Professor Trash" will be easily distinguished from the rest.

```{r, message=FALSE}
Gwynnda_df = 
  readxl::read_excel("202309 Trash Wheel Collection Data.xlsx",
  sheet = "Gwynnda Trash Wheel",   #read the dataset with sheet and range
  range = "A2:L157") |>
  janitor::clean_names() |>   #clean the names
  drop_na("dumpster") |>   #omit na values
  mutate(homes_powered = weight_tons*500/30,   #calculate the homes_powered variable
         additional_dataset = "Gwynnda Trash")   #specify the dataset
```

```{r, message=FALSE}
Gwynnda_cigarette =
  filter(Gwynnda_df, month == "July" & year == 2021)
  sum(Gwynnda_cigarette$cigarette_butts)
```

#### Description of Gwynnda_df:
This Gwynnda_df dataset contains `r nrow(Gwynnda_df)` observations and `r names(Gwynnda_df)` variables. The total number of cigarette butts collected by Gwynnda in July of 2021 is `r sum(Gwynnda_cigarette$cigarette_butts)`. The variable "homes_powered" is calculated using the existing variable "weight_tons" to determine each ton of trash equates to, on average 500 kilowatts of electricity an average household will use 30 kilowatts per day. The additional variable of "additional_dataset" specifies the corresponding data to the "Gwynnda Trash" category. This way, after merging the three datasets, "Gwynnda Trash" will be easily distinguished from the rest.

```{r, message=FALSE}
Combine_TrashWheel = 
  bind_rows(Wheel_df, Professor_df, Gwynnda_df)   #combine three datasets
```

#### Description of Combine_TrashWheel:
This dataset combines three datasets of Wheel_df, Professor_df, and Gwynnda_df with a total of `r nrow(Combine_TrashWheel)` observations and `r names(Combine_TrashWheel)` variables. The additional variable of "additional_dataset" specifies each of the three corresponding categories.


# Problem 3

```{r, message=FALSE}
baseline_mci_df = 
  read_csv("data_mci/MCI_baseline.csv", skip = 1, na = ".") |>   #read the dataset as na
  janitor::clean_names() |>   #clean the names
  mutate(   #mutate sex and apoe4 variables
    sex = replace(sex, sex == 0, "Female"),
    sex = replace(sex, sex == 1, "Male"), 
    apoe4 = replace(apoe4, apoe4 == 1, "Yes"),
    apoe4 = replace(apoe4, apoe4 == 0, "No")
  ) |>   
  filter(!(current_age >= age_at_onset | is.na(age_at_onset)))   #remove the participants who don't develop MCI or have already developed MCI before the study
```

```{r, message=FALSE}
baseline_recruited_df = 
  read_csv("data_mci/MCI_baseline.csv", skip = 1, na = ".") |>   #read the dataset as na
  janitor::clean_names() |>   #clean the names
  mutate(   #mutate sex and apoe4 variables
    sex = replace(sex, sex == 0, "Female"),
    sex = replace(sex, sex == 1, "Male"), 
    apoe4 = replace(apoe4, apoe4 == 1, "Yes"),
    apoe4 = replace(apoe4, apoe4 == 0, "No")
  )  
  filter(baseline_recruited_df, current_age < age_at_onset | is.na(age_at_onset))   #keep the participants who develop or do not develop MCI, i.e. remove the participants who have already developed MCI before the study
```

```{r, message=FALSE}
Average_age =
  pull(baseline_recruited_df, current_age)
  mean(Average_age)   #calculate the mean of the baseline age
```

```{r, message=FALSE}
filter(baseline_recruited_df, sex == "Female" & apoe4 == "Yes")   #select females who are apoe4 carriers
filter(baseline_recruited_df, sex == "Female")   #select females
```

Proportion calculation:
63/211 = 0.298 = 29.8%

#### Description of the important steps:
There were 479 participants recruited for this study. Of these recruited, 93 participants develop MCI. The average baseline age is 65.04679 years old. 29.8% of women in the study are APOE4 carriers.

```{r, message=FALSE}
amyloid_df =
  read_csv("data_mci/mci_amyloid.csv", skip = 1) |>   #read the dataset of amyloid
  janitor::clean_names() |>   #clean the names
  rename(id = study_id) |>   #rename to make the variable consistent
  pivot_longer(   #extend the dataset
    time_2:time_8,
    names_to = "time",
    values_to = "value"
  )
```

#### Comment on the steps and dataset:
The variable "pivot_longer" is implemented to extend the dataset longer instead of wider. The variable "study_id" in the original file "mci_amyloid.csv" is not consistent, so it is rewritten into "id". This step is important to better find data after combing both dataset of "mci_amyloid.csv" and "MCI_baseline.csv".

```{r, message=FALSE}
Combine_Participant = 
  inner_join(baseline_mci_df, amyloid_df, by = "id")   #join two dataset by id
write.csv(Combine_Participant, "Combine_Participant.csv")   #export the dataset
```

#### Description of Combine_Participant:
There are some of the participants that only appear in the baseline or in amyloid dataset based on the id variable. The first missing "id" in amyloid but appear in baseline is id 14. By joining two dataset together, the Combine_Participant dataset contains `r nrow(Combine_Participant)` observations and `r names(Combine_Participant)` variables, and `r nrow(Combine_Participant)/4` participants appear in both dataset at the same time.
